(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[465],{8502:function(e,t,i){(window.__NEXT_P=window.__NEXT_P||[]).push(["/research",function(){return i(2011)}])},6539:function(e,t,i){"use strict";i.d(t,{Z:function(){return m}});var n,a,s=i(1799),r=i(9396),o=i(9534),c=i(5893),l=i(1664),d=i.n(l),h=i(6010);function u(e){return(0,c.jsx)("svg",(0,r.Z)((0,s.Z)({viewBox:"0 0 16 16",fill:"none","aria-hidden":"true"},e),{children:(0,c.jsx)("path",{d:"M6.75 5.75 9.25 8l-2.5 2.25",strokeWidth:"1.5",strokeLinecap:"round",strokeLinejoin:"round"})}))}function m(e){var t=e.as,i=e.className,n=e.children;return(0,c.jsx)(void 0===t?"div":t,{className:(0,h.Z)(i,"group relative flex flex-col items-start"),children:n})}n=function(e){var t=e.children,i=(0,o.Z)(e,["children"]);return(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)("div",{className:"absolute -inset-y-6 -inset-x-4 z-0 scale-95 bg-zinc-50 opacity-0 transition group-hover:scale-100 group-hover:opacity-50 dark:bg-zinc-800/50 sm:-inset-x-6 sm:rounded-2xl"}),(0,c.jsxs)(d(),(0,r.Z)((0,s.Z)({},i),{children:[(0,c.jsx)("span",{className:"absolute -inset-y-6 -inset-x-4 z-20 sm:-inset-x-6 sm:rounded-2xl"}),(0,c.jsx)("span",{className:"relative z-10",children:t})]}))]})},m.Link=n,m.Title=function(e){var t=e.as,i=e.href,n=e.children;return(0,c.jsx)(void 0===t?"h2":t,{className:"text-lg font-semibold tracking-tight text-zinc-800 dark:text-zinc-100",children:i?(0,c.jsx)(m.Link,{href:i,children:n}):n})},m.Description=function(e){var t=e.children;return(0,c.jsx)("p",{className:"relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400",children:t})},m.Cta=function(e){var t=e.children;return(0,c.jsxs)("div",{"aria-hidden":"true",className:"relative z-10 mt-4 flex items-center text-sm font-medium dark:text-blue-400 dark:hover:text-blue-500 hover:text-blue-600 text-blue-500",children:[t,(0,c.jsx)(u,{className:"ml-1 h-4 w-4 stroke-current"})]})},a=function(e){var t=e.as,i=e.decorate,n=void 0!==i&&i,a=e.className,l=e.children,d=(0,o.Z)(e,["as","decorate","className","children"]);return(0,c.jsxs)(void 0===t?"p":t,(0,r.Z)((0,s.Z)({className:(0,h.Z)(a,"relative z-10 order-first mb-3 flex items-center text-sm text-zinc-400 dark:text-zinc-400",n&&"pl-3.5")},d),{children:[n&&(0,c.jsx)("span",{className:"absolute inset-y-0 left-0 flex items-center","aria-hidden":"true",children:(0,c.jsx)("span",{className:"h-4 w-0.5 rounded-full bg-zinc-200 dark:bg-zinc-400"})}),l]}))},m.Eyebrow=a},9467:function(e,t,i){"use strict";i.d(t,{$:function(){return s}});var n=i(5893),a=i(7294);function s(e){var t=e.title,i=e.children,s=(0,a.useId)();return(0,n.jsx)("section",{"aria-labelledby":s,className:"md:border-l md:border-zinc-100 md:pl-6 md:dark:border-zinc-700/40",children:(0,n.jsxs)("div",{className:"grid max-w-3xl grid-cols-1 items-baseline gap-y-8 md:grid-cols-4",children:[(0,n.jsx)("h2",{id:s,className:"text-sm font-semibold text-zinc-800 dark:text-zinc-100",children:t}),(0,n.jsx)("div",{className:"md:col-span-3",children:i})]})})}},1439:function(e,t,i){"use strict";i.d(t,{X:function(){return s}});var n=i(5893),a=i(956);function s(e){var t=e.title,i=e.intro,s=e.children;return(0,n.jsxs)(a.W,{className:"mt-16 sm:mt-32",children:[(0,n.jsxs)("header",{className:"max-w-2xl",children:[(0,n.jsx)("h1",{className:"text-4xl font-bold tracking-tight text-zinc-800 dark:text-zinc-100 sm:text-5xl",children:t}),(0,n.jsx)("p",{className:"mt-6 text-base text-zinc-600 dark:text-zinc-400",children:i})]}),(0,n.jsx)("div",{className:"mt-16 sm:mt-20",children:s})]})}},2011:function(e,t,i){"use strict";i.r(t),i.d(t,{default:function(){return p}});var n=i(1799),a=i(9396),s=i(9534),r=i(5893),o=i(9008),c=i.n(o),l=i(6539),d=i(9467),h=i(1439);function u(e){var t=e.children,i=(0,s.Z)(e,["children"]);return(0,r.jsx)(d.$,(0,a.Z)((0,n.Z)({},i),{children:(0,r.jsx)("div",{className:"space-y-16",children:t})}))}function m(e){var t=e.title,i=e.description,n=e.event,a=e.cta,s=e.href;return(0,r.jsxs)(l.Z,{as:"article",children:[(0,r.jsx)(l.Z.Title,{as:"h3",href:s,children:t}),(0,r.jsx)(l.Z.Eyebrow,{decorate:!0,children:n}),(0,r.jsx)(l.Z.Description,{children:i}),a?(0,r.jsx)(l.Z.Cta,{children:a}):null]})}function p(){return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(c(),{children:[(0,r.jsx)("title",{children:"Research - Manish Balamurugan"}),(0,r.jsx)("meta",{name:"description",content:"Manish Balamurugan - AI & Tech Innovation Research"})]}),(0,r.jsx)(h.X,{title:"Here's some of the projects which I fully explored and delved into",intro:"I've designed, implemented, and published various research concepts in the AI/ML space and their intersections in verticals including Healthtech and Business. I'm passionate about ethical AI, precision technology, and quantitative finance.",children:(0,r.jsxs)("div",{className:"space-y-20",children:[(0,r.jsxs)(u,{title:"Publications",children:[(0,r.jsx)(m,{href:"https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11602/116021C/Automatic-detection-of-cotton-balls-during-brain-surgery--where/10.1117/12.2580887.short?SSO=1",title:"Automatic detection of cotton balls during brain surgery: where deep learning meets ultrasound imaging to tackle foreign objects",description:"Cotton balls are a versatile and efficient tool commonly used in neurosurgical procedures to absorb fluids and manipulate delicate tissues. However, the use of cotton balls is accompanied by the risk of accidental retention in the brain after surgery. Retained cotton balls can lead to dangerous immune responses and potential complications, such as adhesions and textilomas. In a previous study, we showed that ultrasound can be safely used to detect cotton balls in the operating area due to the distinct acoustic properties of cotton compared with the acoustic properties of surrounding tissue. In this study, we enhance the experimental setup using a 3D-printed custom depth box and a Butterfly IQ handheld ultrasound probe. Cotton balls were placed in variety of positions to evaluate size and depth detectability limits. Recorded images were then analyzed using a novel algorithm that implements recently released...",event:"Medical Imaging 2021: Ultrasonic Imaging and Tomography 11602, 295-302",cta:"View Publication"}),(0,r.jsx)(m,{href:"https://watermark.silverchair.com/v001t02a001-dmd2020-9109.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAABAYwggQCBgkqhkiG9w0BBwagggPzMIID7wIBADCCA-gGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMd4MhkWH7G7Ur-sZkAgEQgIIDuUiFVijZGUVGr275Vs53h-0P9yrqrDPdBe8kmMMkzInCmx88NkvFX5nU1kH1A5vU2xo9TQIIquYcUoKk_q7KF0HHVqpr3Xmp93yuC__0GFjG2mHRI8d1VFJKbPDsi505hTCO5DBKL52cRNKxRjEsqLeLUZV2Hy7Wy_XgDX5OU4E3d4e8KN-M005PjUDdQaEueFWU2hxinGMESN8mm5smTD64pXHtE-jquCGoRL-TCX7V0c0cP9EapwnJ__lg_XYTr6CRL1JzB2BsMDR1PLhnsAvWEJgFJbvHzI3lcps1hc1Cf1fbKx9LROWgw62uP49wYVruXyNA2IQZlOMFw_HkOwLMd6c_znzU5qptW4RD2eu038nGI8s6cABG1qFDPmO5PZd6wmAgGFCwG9S2g_VbJ2ZAvxhBffU0p2b5Y7Pf1ItieGlXblTfu65o1Z7pGonLPdWyVM_ONXheEUTehhO5fqYX6XYA4OBSqb6RnPeZ_YcpR8WwAH1jbfnCJr7rKPWdTD-NFpjcPhR9DeyhCRaaATI2_7fv4OC9yke6frdPb6UbLp0hepAXI3nWYUKU7WbL2TkHbKFbPViMO05ObZnWOp6PeVrjXfKQcjfsgasbz0-LI3mLcDXD2hnLg1bhHNlYj_mniOegmbd9XllnibA-w7wSzHNp-C600miJJr6qIPoELm97o9gitVOR43OUkchfl3xXXnHShEF-QEHXpcmcZvg5clEjhal1DQOif7kSw5WsOX2fKQt1UYFhCvf4-vCunHuig4tZAIq1aiiPNnwE60wfMcDfrwY-zrhsLajgIcPvMvw7Vm4qeHWApRDyuRGGvzIix1_0rok7wohW9OUb60tq4bbKh6bPvhKtaeZ6Bwi8zrseobar2b0UeXCX1c1-IeKWFsvC37xX8dJEohF6_rdDHumGIPhEbLjgHz_hcQ_1iTIzVt69pxEDN36oIfyFiUgFkusgj-_KG0Qby3CLRL0kSBnGK1qR5zEGYc0S6VykGHo90CrOvMiY2tsHJlo6ZQVSQpw96q7TsBbAiypFNDzDfBbsqrO9bIX0JK9kpnMomadKbyb2oVLgM3mCs2ruVSiS80BXp24Oj63RtWC30qsHc45o2XJz57DbzcImslXOQxD4CjyODaIYFpT9DWOsCTaRnMd9DA2MYtcVQEZ6oTj_0a4V7qS3PY_3RSOVNtA90PJCTNMnZGQF67yi0eqJM82yO4djdOVptFfgFO6oDKcaysJFp-bAGArqr6j1Ql0wf0BshlnsI5Yk",title:"USDL: Inexpensive medical imaging using deep learning techniques and ultrasound technology",description:"In this study, we present USDL, a novel model that employs deep learning algorithms in order to reconstruct and enhance corrupted ultrasound images. We utilize an unsupervised neural network called an autoencoder which works by compressing its input into a latent-space representation and then reconstructing the output from this representation. We trained our model on a dataset that compromises of 15,700 in vivo images of the neck, wrist, elbow, and knee vasculature and compared the quality of the images generated using the structural similarity index (SSIM) and peak to noise ratio (PSNR). In closely simulated conditions, the architecture exhibited an average reconstruction accuracy of 90% as indicated by our SSIM. Our study demonstrates that USDL outperforms state of the art image enhancement and reconstruction techniques in both image quality and computational complexity, while maintaining...",event:"American Society of Mechanical Engineers",cta:"View Publication"})]}),(0,r.jsxs)(u,{title:"Projects & Discussion",children:[(0,r.jsx)(m,{href:"/ml4va.pdf",title:"ML4VA: A Machine Learning-based Approach for Diabete Detection",description:"In this paper, we compared the performance of various machine learning models including Logistic Regression, Random Forest, and Convolutional Neural Networks (CNN), in order to create a prediciton tool that is able to function as a diabetic predictor. Virginia’s diabetes rate is on par with the national average and growing quickly. In recent years, we’ve also seen a rise in the proportion of the population that can be classified as prediabetic. However, Type 2 diabetes is preventable with lifestyle changes and proper treatment. For this project we have decided to tackle the challenge of determining whether an individual is at risk of diabetes in order to ensure that they can undergo the proper screening, treatment, and life style changes in order to properly control this disease before serious com- plications arise. In this project we employ various classification models and experiment with optimizers and error functions to achieve the highest precision model. We believe that identifying an individuals likelihood for contracting di- abetes may encourage Virginians to consider lifestyle changes and reduce our state’s diabetic rate in the future.",event:"UVA CS 4744 Machine Learning",cta:"View Paper"}),(0,r.jsx)(m,{href:"/ai-hallucination.pdf",title:"ChatGPT, Generative AI, & AI Hallucinations",description:"Artificial Intelligence (AI) has been a hot topic of discussion since the turn of the last century, and within the last decade there has been rapid advances within the space including general public access to state of the art models. Within the last year, the generative AI space - a subset of AI systems which can be utilized to generate content including images, audio, code, and simulations - has been rapidly adopted throughout various sectors including healthcare, finance, transportation, and retail.[2] The surge in open-source access of big data and computing resources can be linked to the wider accessibility of open source resources for AI model development. Integrated systems such as GPT have shown the capability of being utilized in larger systems and business use-cases, and the performance of this technology continues to advance rapidly everyday through the efforts of large corporations such as OpenAI and Microsoft along with the efforts of independent researchers and AI/ML enthusiasts. Currently, AI systems such as GPT, LLAMA, HuggingFace-GPT, have reached a stage where the capabilities of these systems are not only capable of performing simple tasks but is also fully stable in higher-level task requiring object recognition, natural language processing, and decision-making with the ability to generate human-like responses...",event:"UVA PHIL 1410 Forms of Reasoning",cta:"View Paper"})]})]})})]})}},9008:function(e,t,i){e.exports=i(5443)}},function(e){e.O(0,[774,888,179],function(){return e(e.s=8502)}),_N_E=e.O()}]);